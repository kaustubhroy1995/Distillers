# Distillers
A brief foray into Deep Learning Model Distillation network designs. This is meant to start as a personal exploration in the topic of model distillation and hopefully evolve into a library seamlessly incorporating various model distillation methodologies proposed and developed over the years

This library will be written in and support pytorch models
